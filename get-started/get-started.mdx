---
title: "Welcome to the Inception Platform"
description: "Inception Platform provides powerful AI capabilities through an OpenAI-compatible API interface. This means you can use existing OpenAI client libraries or direct REST calls to access our services."
sidebarTitle: "Quick Start"
---

## Account Setup

1. Create an Inception Platform account or [sign in](https://platform.inceptionlabs.ai/auth/login) directly if you already have one.

   âœ¨ Each new user is initially assigned **10 million free tokens** to help get started with the API.
2. Go to [API Keys](https://platform.inceptionlabs.ai/dashboard/api-keys) and create a new API key. You can start using the API immediately with your free tokens!
3. When your free tokens are running low, navigate to [Billing](https://platform.inceptionlabs.ai/dashboard/billing) to add your payment information for continued usage beyond the free tier.

## Quick Start

All API requests should be made to:

```
https://api.inceptionlabs.ai/v1
```

All API requests should be sent with the API key in the Authorization header:

```
Authorization: Bearer INCEPTION_API_KEY
```

All requests should be sent as JSON with the appropriate content type header:

```
Content-Type: application/json
```

#### **Examples**

<CodeGroup>

```python Python
import requests

response = requests.post(
    'https://api.inceptionlabs.ai/v1/chat/completions',
    headers={
        'Content-Type': 'application/json',
        'Authorization': 'Bearer INCEPTION_API_KEY'
    },
    json={
        'model': 'mercury',  
        'messages': [
            {'role': 'user', 'content': 'What is a diffusion model?'}
        ],
        'max_tokens': 1000
    }
)
data = response.json()
```


```bash cURL
curl https://api.inceptionlabs.ai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer INCEPTION_API_KEY" \
  -d '{
    "model": "mercury",
    "messages": [
      {"role": "user", "content": "What is a diffusion model?"}
    ],
    "max_tokens": 1000
  }'
```


```javascript JavaScript
// Using fetch API
const response = await fetch('https://api.inceptionlabs.ai/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer INCEPTION_API_KEY'
  },
  body: JSON.stringify({
    model: 'mercury',
    messages: [
      { role: 'user', content: 'What is a diffusion model?' }
    ],
    max_tokens: 1000
  })
});
const data = await response.json();
```


```TypeScript TypeScript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: 'INCEPTION_API_KEY',
  baseURL: 'https://api.inceptionlabs.ai/v1'
});

const response = await openai.chat.completions.create({
  model: 'mercury',
  messages: [
    { role: 'user', content: 'What is a diffusion model?' }
  ],
  max_tokens: 1000
});
```

</CodeGroup>

#### **External Libraries Compatibility**

Inception API is fully compatible with popular Python libraries:

<CodeGroup>

```python OpenAI Client
from openai import OpenAI

client = OpenAI(
    api_key="INCEPTION_API_KEY",
    base_url="https://api.inceptionlabs.ai/v1"
)

response = client.chat.completions.create(
    model="mercury",
    messages=[{"role": "user", "content": "What is a diffusion model?"}],
    max_tokens=1000
)
print(response.choices[0].message.content)
```


```python AISuite
import aisuite as ai

client = ai.Client(
    {
        "openai": {"api_key": "INCEPTION_API_KEY", "base_url": "https://api.inceptionlabs.ai/v1"},
    }
)

response = client.chat.completions.create(
    model="openai:mercury",
    messages=[{"role": "user", "content": "What is a diffusion model?"}],
    max_tokens=1000
)
print(response.choices[0].message.content)
```


```python LiteLLM
from litellm import completion

response = completion(
    model="openai/mercury",
    messages=[{"role": "user", "content": "What is a diffusion model?"}],
    api_key="INCEPTION_API_KEY",
    api_base="https://api.inceptionlabs.ai/v1",
    max_tokens=1000
)
print(response.choices[0].message.content)
```


```python LangChain
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

llm = ChatOpenAI(
    model="mercury",
    temperature=0,
    api_key="INCEPTION_API_KEY",
    base_url="https://api.inceptionlabs.ai/v1"
)
llm.invoke([("user", "What is a diffusion model?")])
```

</CodeGroup>